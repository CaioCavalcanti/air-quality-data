name: Publish Python Package air-quality-spark

on:
  push:
    branches:
      - "main"
    paths:
      - ".github/workflows/publish-spark-package.yaml"
      - "spark/air-quality-spark/**"

jobs:
  build-and-publish:
    name: Build and Publish Python Package air-quality-spark
    permissions:
      contents: "read"
      id-token: "write"
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: spark/air-quality-spark/
    env:
      GCP_WORKLOAD_IDENTITY_PROVIDER: "${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}"
      GCP_DEVOPS_SERVICE_ACCOUNT: "${{ secrets.GCP_DEVOPS_SERVICE_ACCOUNT }}"
      GCP_PROJECT_ID: "${{ secrets.GCP_PROJECT_ID }}"
      GCP_PYTHON_REPOSITORY_NAME: "${{ secrets.GCP_PYTHON_REPOSITORY_NAME }}"
      GCP_REGION: "${{ secrets.GCP_REGION }}"

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: 3.9
          cache: "pip"

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Build Package
        run: |
          python setup.py bdist_wheel

      - name: "Authenticate to Google Cloud"
        uses: "google-github-actions/auth@v1"
        with:
          workload_identity_provider: ${{ env.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ env.GCP_DEVOPS_SERVICE_ACCOUNT }}

      - name: "Set up Google Cloud SDK"
        uses: "google-github-actions/setup-gcloud@v1"

      - name: Upload to Artifact Registry
        run: |
          gcloud artifacts print-settings python --project=${GCP_PROJECT_ID} --repository=${GCP_PYTHON_REPOSITORY_NAME} --location=${GCP_REGION} > ~/.pypirc
          python -m twine upload --repository https://${GCP_REGION}-python.pkg.dev/${GCP_PROJECT_ID}/${GCP_PYTHON_REPOSITORY_NAME}/ dist/*
